# Fast Image Training with FastAI!

Learning the process to classify 10 different classes of animal proved to be very user friendly thanks to the simplicity of FastAI and the well managed introductory courses. 

## Resnet (18) - Pre-trained Data

Initially following the course material and experimenting with FastAI, I was anticipating a long process of having to classify my own data. 
Specifically, this entailed what seemed like a repetivive process of verrifying correct image analysis for the training data to be effective.

However, the utilisatiion of [Resnet18](https://pytorch.org/vision/main/models/generated/torchvision.models.resnet18.html) completely changed this approach, providing a far easier and more time efficient solution. 
ResNet-18 is a convolutional neural network (CNN) that is 18 layers deep. Specifically, it is pretrained across a wide range of data, which can exceed one million images and allows classification of defined image characteristics.

This was vital to the implementation explored in the ELEC4630 assignment, as the small dataset of approximately 200 images per animal would struggle generating its own complete training set and classification system. 

## Fine Tuning

While Resnet18 provides a pre-trained dataset, it needs to be adjusted and tailored to the animal data generated. Specifically, Convolutional Neural Networks have already been developed from the Resnet18 data using Transfer Learning techniques. 

[Fine Tuning](https://www.analyticsvidhya.com/blog/2021/05/training-state-of-the-art-deep-learning-models-with-fast-ai/) is a method that allows this to be performed and operates through Transfer Learning.

Hence, following these processes, the pre-trained data can be adjusted to the actual dataset used allowing a more [efficient](https://huggingface.co/docs/transformers/main/training) and effective solution. 


<img src="/images/a4.png"

     
As shown in the Table above, iterating over number of epochs deminstrates the classification accuracy of the dataset over a number of fine-tuning iterations. 
     
- I observe the phenomenon of 'over training' which results in an 'overfit', which is observed where the accuracy drops despite 
